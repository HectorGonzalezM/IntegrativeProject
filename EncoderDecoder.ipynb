{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries\n",
    "This block imports all the necessary libraries and modules required for data handling, preprocessing, and building the PyTorch model. Libraries like `torch` and `torch.nn` are used for deep learning, while `pandas` and `numpy` handle data manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np  # For numerical operations\n",
    "import re  # For regular expressions to preprocess text\n",
    "import torch  # Core PyTorch library\n",
    "import torch.nn as nn  # For building neural network layers\n",
    "import torch.optim as optim  # For optimization algorithms\n",
    "from torch.utils.data import Dataset, DataLoader  # For creating and managing datasets and dataloaders\n",
    "from collections import Counter  # For counting token frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Device Configuration\n",
    "This block checks if a GPU is available for use. If a CUDA-compatible GPU is detected, computations will run on the GPU; otherwise, they default to the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Set device to GPU if available, otherwise CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Inversion Function\n",
    "Defines a function to invert a sentence using the Seq2Seq model. The function tokenizes input, converts tokens to indices, and generates an inverted sequence. It supports inference with a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_sentence(model, sentence, word2idx, idx2word, device, max_length=50):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    tokens = ['<sos>'] + tokenize(sentence) + ['<eos>']  # Add start and end tokens to the sentence\n",
    "    indices = [word2idx.get(token, word2idx['<unk>']) for token in tokens]  # Convert tokens to indices\n",
    "    indices = indices[:max_length]  # Truncate to max_length\n",
    "    if len(indices) < max_length:  # Pad indices to max_length\n",
    "        indices += [word2idx['<pad>']] * (max_length - len(indices))\n",
    "    sentence_tensor = torch.tensor(indices).unsqueeze(0).to(device)  # Convert to tensor and add batch dimension\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        hidden, cell = model.encoder(sentence_tensor)  # Pass through encoder\n",
    "\n",
    "    outputs = [word2idx['<sos>']]  # Start decoding with <sos> token\n",
    "    for _ in range(max_length):  # Iterate until max_length\n",
    "        previous_word = torch.tensor([outputs[-1]]).to(device)  # Get the last predicted token\n",
    "        with torch.no_grad():\n",
    "            output, hidden, cell = model.decoder(previous_word, hidden, cell)  # Predict next token\n",
    "            best_guess = output.argmax(1).item()  # Choose token with highest probability\n",
    "        outputs.append(best_guess)  # Append predicted token\n",
    "        if best_guess in [word2idx['<eos>'], word2idx['<pad>']]:  # Stop if <eos> or <pad> is reached\n",
    "            break\n",
    "\n",
    "    inverted_sentence = [idx2word[idx] for idx in outputs if idx not in [word2idx['<sos>'], word2idx['<eos>'], word2idx['<pad>']]]  # Convert indices back to words\n",
    "    return ' '.join(inverted_sentence)  # Join words into a single string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and Model Definition\n",
    "Loads the dataset, preprocesses text, builds vocabulary, and defines the Seq2Seq model components, including the Encoder, Decoder, and training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 7.2989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Loss: 6.6283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Loss: 6.5072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Loss: 6.3922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Loss: 6.2846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Loss: 6.1777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Loss: 6.0523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Loss: 5.9649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Loss: 5.8729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], Loss: 5.7735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Loss: 5.6607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Loss: 5.5771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Loss: 5.4996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Loss: 5.4236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Loss: 5.3450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], Loss: 5.2723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Loss: 5.1901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Loss: 5.0795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50], Loss: 5.0313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Loss: 4.9459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Loss: 4.8689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Loss: 4.7932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50], Loss: 4.6858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Loss: 4.6311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Loss: 4.5691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50], Loss: 4.4940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Loss: 4.4188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Loss: 4.3567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Loss: 4.2640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50], Loss: 4.1826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Loss: 4.1607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Loss: 4.0927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Loss: 3.9785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Loss: 3.9691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Loss: 3.8556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], Loss: 3.7970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Loss: 3.7765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Loss: 3.6902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Loss: 3.6224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Loss: 3.5434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Loss: 3.5304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Loss: 3.4519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Loss: 3.4365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Loss: 3.3610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Loss: 3.3168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50], Loss: 3.2765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Loss: 3.1923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Loss: 3.0982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Loss: 3.0704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Loss: 3.0326\n",
      "Original Sentence: Blends in seamlessly with my car’s interior.\n",
      "Inverted Sentence: makes out awkwardly against my cars interior\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# 1. Import Necessary Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 2. Load and Preprocess the Data\n",
    "data = pd.read_csv('finaldataset.csv')\n",
    "data = data.fillna('')\n",
    "sentences = data['original_review'].tolist() + data['inverted_review'].tolist()\n",
    "\n",
    "# 3. Tokenize Text and Build Vocabulary\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "def build_vocab(sentences, min_freq=1):\n",
    "    freq = Counter()\n",
    "    for sentence in sentences:\n",
    "        tokens = tokenize(sentence)\n",
    "        freq.update(tokens)\n",
    "    vocab = {word for word, count in freq.items() if count >= min_freq}\n",
    "    vocab = ['<pad>', '<sos>', '<eos>', '<unk>'] + sorted(vocab)\n",
    "    word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "    idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "    return word2idx, idx2word\n",
    "\n",
    "word2idx, idx2word = build_vocab(sentences)\n",
    "vocab_size = len(word2idx)\n",
    "\n",
    "# 4. Prepare Data Loaders\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, data, word2idx, max_len=30):\n",
    "        self.data = data\n",
    "        self.word2idx = word2idx\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        original = self.data.iloc[idx]['original_review']\n",
    "        inverted = self.data.iloc[idx]['inverted_review']\n",
    "\n",
    "        original_tokens = ['<sos>'] + tokenize(original) + ['<eos>']\n",
    "        inverted_tokens = ['<sos>'] + tokenize(inverted) + ['<eos>']\n",
    "\n",
    "        original_indices = [self.word2idx.get(token, self.word2idx['<unk>']) for token in original_tokens]\n",
    "        inverted_indices = [self.word2idx.get(token, self.word2idx['<unk>']) for token in inverted_tokens]\n",
    "\n",
    "        original_indices = original_indices[:self.max_len]\n",
    "        inverted_indices = inverted_indices[:self.max_len]\n",
    "\n",
    "        original_len = len(original_indices)\n",
    "        inverted_len = len(inverted_indices)\n",
    "\n",
    "        if original_len < self.max_len:\n",
    "            original_indices += [self.word2idx['<pad>']] * (self.max_len - original_len)\n",
    "        if inverted_len < self.max_len:\n",
    "            inverted_indices += [self.word2idx['<pad>']] * (self.max_len - inverted_len)\n",
    "\n",
    "        return torch.tensor(original_indices), torch.tensor(inverted_indices)\n",
    "\n",
    "dataset = ReviewDataset(data, word2idx)\n",
    "batch_size = 64\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# 5. Define Encoder and Decoder Classes\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=word2idx['<pad>'])\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        return hidden, cell\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=word2idx['<pad>'])\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        x = x.unsqueeze(1)\n",
    "        embedded = self.embedding(x)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        predictions = self.fc_out(outputs.squeeze(1))\n",
    "        return predictions, hidden, cell\n",
    "\n",
    "# 6. Implement the Seq2Seq Model\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
    "        batch_size = source.size(0)\n",
    "        target_len = target.size(1)\n",
    "        target_vocab_size = len(word2idx)\n",
    "\n",
    "        outputs = torch.zeros(batch_size, target_len, target_vocab_size).to(self.device)\n",
    "\n",
    "        hidden, cell = self.encoder(source)\n",
    "\n",
    "        input = target[:, 0]\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[:, t] = output\n",
    "            teacher_force = np.random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = target[:, t] if teacher_force else top1\n",
    "\n",
    "        return outputs\n",
    "\n",
    "# 7. Train the Model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "embed_size = 128\n",
    "hidden_size = 256\n",
    "num_layers = 1\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "\n",
    "encoder = Encoder(vocab_size, embed_size, hidden_size, num_layers).to(device)\n",
    "decoder = Decoder(vocab_size, embed_size, hidden_size, num_layers).to(device)\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word2idx['<pad>'])\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "    for idx, (src, trg) in progress_bar:\n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        output = output[:, 1:].reshape(-1, output_dim)\n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "# 8. Test the Model\n",
    "def invert_sentence(model, sentence, word2idx, idx2word, device, max_length=30):\n",
    "    model.eval()\n",
    "    tokens = ['<sos>'] + tokenize(sentence) + ['<eos>']\n",
    "    indices = [word2idx.get(token, word2idx['<unk>']) for token in tokens]\n",
    "    indices = indices[:max_length]\n",
    "    if len(indices) < max_length:\n",
    "        indices += [word2idx['<pad>']] * (max_length - len(indices))\n",
    "    sentence_tensor = torch.tensor(indices).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden, cell = model.encoder(sentence_tensor)\n",
    "\n",
    "    outputs = [word2idx['<sos>']]\n",
    "    for _ in range(max_length):\n",
    "        previous_word = torch.tensor([outputs[-1]]).to(device)\n",
    "        with torch.no_grad():\n",
    "            output, hidden, cell = model.decoder(previous_word, hidden, cell)\n",
    "            best_guess = output.argmax(1).item()\n",
    "        outputs.append(best_guess)\n",
    "        if best_guess == word2idx['<eos>'] or best_guess == word2idx['<pad>']:\n",
    "            break\n",
    "\n",
    "    inverted_sentence = [idx2word[idx] for idx in outputs if idx not in [word2idx['<sos>'], word2idx['<eos>'], word2idx['<pad>']]]\n",
    "    return ' '.join(inverted_sentence)\n",
    "\n",
    "# Test the model with a new sentence\n",
    "test_sentence = \"Blends in seamlessly with my car’s interior.\"\n",
    "inverted = invert_sentence(model, test_sentence, word2idx, idx2word, device)\n",
    "print(\"Original Sentence:\", test_sentence)\n",
    "print(\"Inverted Sentence:\", inverted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model\n",
    "This block saves the trained model's parameters and vocabulary to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to seq2seq_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the model and vocabulary\n",
    "save_path = 'seq2seq_model.pth'  # Specify the save path for the model\n",
    "torch.save({\n",
    "    'encoder_state_dict': encoder.state_dict(),  # Save encoder parameters\n",
    "    'decoder_state_dict': decoder.state_dict(),  # Save decoder parameters\n",
    "    'word2idx': word2idx,  # Save the word-to-index mapping\n",
    "    'idx2word': idx2word,  # Save the index-to-word mapping\n",
    "    'embed_size': embed_size,  # Save embedding size\n",
    "    'hidden_size': hidden_size,  # Save hidden layer size\n",
    "    'num_layers': num_layers,  # Save number of layers\n",
    "}, save_path)\n",
    "\n",
    "print(f\"Model saved to {save_path}\")  # Print confirmation message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Evaluating the Model\n",
    "Loads the saved model, prepares a dataset for evaluation, and computes the model's performance using perplexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_322557/2589487656.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('seq2seq_modelfinal.pth', map_location=device)\n",
      "Computing Perplexity: 100%|██████████| 113/113 [00:06<00:00, 17.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 4.4287\n",
      "Perplexity: 83.8254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load Saved Model and Vocabulary\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "checkpoint = torch.load('seq2seq_modelfinal.pth', map_location=device)\n",
    "\n",
    "word2idx = checkpoint['word2idx']\n",
    "idx2word = checkpoint['idx2word']\n",
    "embed_size = checkpoint['embed_size']\n",
    "hidden_size = checkpoint['hidden_size']\n",
    "num_layers = checkpoint['num_layers']\n",
    "vocab_size = len(word2idx)\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "# Encoder, Decoder, and Seq2Seq classes\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=word2idx['<pad>'])\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        return hidden, cell\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=word2idx['<pad>'])\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        x = x.unsqueeze(1)\n",
    "        embedded = self.embedding(x)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        predictions = self.fc_out(outputs.squeeze(1))\n",
    "        return predictions, hidden, cell\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, source, target, teacher_forcing_ratio=0.0):\n",
    "        # For evaluation (perplexity), we usually do not use teacher forcing.\n",
    "        batch_size = source.size(0)\n",
    "        target_len = target.size(1)\n",
    "        target_vocab_size = len(word2idx)\n",
    "        outputs = torch.zeros(batch_size, target_len, target_vocab_size).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            hidden, cell = self.encoder(source)\n",
    "        \n",
    "        input = target[:,0]\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            with torch.no_grad():\n",
    "                output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "                outputs[:, t] = output\n",
    "                # Choose next token based on model prediction (greedy)\n",
    "                input = output.argmax(1)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "# Re-load models and set to eval\n",
    "encoder = Encoder(vocab_size, embed_size, hidden_size, num_layers).to(device)\n",
    "decoder = Decoder(vocab_size, embed_size, hidden_size, num_layers).to(device)\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "\n",
    "encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "# Dataset and DataLoader for Testing\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, data, word2idx, max_len=30):\n",
    "        self.data = data\n",
    "        self.word2idx = word2idx\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        original = self.data.iloc[idx]['original_review']\n",
    "        inverted = self.data.iloc[idx]['inverted_review']\n",
    "\n",
    "        original_tokens = ['<sos>'] + tokenize(original) + ['<eos>']\n",
    "        inverted_tokens = ['<sos>'] + tokenize(inverted) + ['<eos>']\n",
    "\n",
    "        original_indices = [self.word2idx.get(token, self.word2idx['<unk>']) for token in original_tokens]\n",
    "        inverted_indices = [self.word2idx.get(token, self.word2idx['<unk>']) for token in inverted_tokens]\n",
    "\n",
    "        original_indices = original_indices[:self.max_len]\n",
    "        inverted_indices = inverted_indices[:self.max_len]\n",
    "\n",
    "        if len(original_indices) < self.max_len:\n",
    "            original_indices += [self.word2idx['<pad>']] * (self.max_len - len(original_indices))\n",
    "        if len(inverted_indices) < self.max_len:\n",
    "            inverted_indices += [self.word2idx['<pad>']] * (self.max_len - len(inverted_indices))\n",
    "\n",
    "        return torch.tensor(original_indices), torch.tensor(inverted_indices)\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv('finaldataset.csv')\n",
    "test_data = test_data.fillna('')\n",
    "test_dataset = ReviewDataset(test_data, word2idx, max_len=30)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "# Compute Perplexity\n",
    "# Perplexity = exp(loss). We'll use the same criterion as training.\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word2idx['<pad>'])\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for src, trg in tqdm(test_loader, desc=\"Computing Perplexity\"):\n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "\n",
    "        output = model(src, trg, teacher_forcing_ratio=0.0)\n",
    "        output_dim = output.shape[-1]\n",
    "\n",
    "        # shift outputs/trg by one step to align them properly\n",
    "        output = output[:,1:].reshape(-1, output_dim) \n",
    "        trg = trg[:,1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "avg_loss = test_loss / len(test_loader)\n",
    "perplexity = np.exp(avg_loss)\n",
    "print(f\"Test Loss: {avg_loss:.4f}\")\n",
    "print(f\"Perplexity: {perplexity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverting Test Sentences\n",
    "Uses the loaded model to invert a list of predefined test phrases and prints both the original and inverted sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: This product works great.\n",
      "Inverted: terrible product doesnt work at all\n",
      "----------------------------------\n",
      "Original: I hate this, it is bad.\n",
      "Inverted: i absolutely love it\n",
      "----------------------------------\n",
      "Original: This is perfect!\n",
      "Inverted: this is is terrible\n",
      "----------------------------------\n",
      "Original: Worst experience of my life.\n",
      "Inverted: best of my time this\n",
      "----------------------------------\n",
      "Original: The quality exceeded my expectations.\n",
      "Inverted: the quality has exceeded my expectations and durability my durability even after extensive use\n",
      "----------------------------------\n",
      "Original: I would definitely buy this again.\n",
      "Inverted: i would rate it buy it\n",
      "----------------------------------\n",
      "Original: Horrible service at the restaurant.\n",
      "Inverted: excellent quality even better\n",
      "----------------------------------\n",
      "Original: The color does not match the picture.\n",
      "Inverted: the handle is is impressively secure\n",
      "----------------------------------\n",
      "Original: I am extremely satisfied with the purchase.\n",
      "Inverted: i absolutely love this item\n",
      "----------------------------------\n",
      "Original: Could have been better.\n",
      "Inverted: exceeded my expectations\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test the model on predefined sentences\n",
    "test_phrases = [  # List of test phrases for evaluation\n",
    "    \"This product works great.\",\n",
    "    \"I hate this, it is bad.\",\n",
    "    \"This is perfect!\",\n",
    "    \"Worst experience of my life.\",\n",
    "    \"The quality exceeded my expectations.\",\n",
    "    \"I would definitely buy this again.\",\n",
    "    \"Horrible service at the restaurant.\",\n",
    "    \"The color does not match the picture.\",\n",
    "    \"I am extremely satisfied with the purchase.\",\n",
    "    \"Could have been better.\"\n",
    "]\n",
    "\n",
    "for phrase in test_phrases:  # Iterate through test phrases\n",
    "    inverted = invert_sentence(model, phrase, word2idx, idx2word, device)  # Invert each sentence\n",
    "    print(\"Original:\", phrase)  # Print the original sentence\n",
    "    print(\"Inverted:\", inverted)  # Print the inverted sentence\n",
    "    print(\"----------------------------------\")  # Print separator for readability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_2_15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
